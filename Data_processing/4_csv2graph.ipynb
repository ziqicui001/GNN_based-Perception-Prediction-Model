{"cells":[{"cell_type":"code","execution_count":null,"id":"01a88c47-7303-4dc6-8d4a-a736e8684788","metadata":{"id":"01a88c47-7303-4dc6-8d4a-a736e8684788"},"outputs":[],"source":["import os\n","import pandas as pd\n","import torch\n","from torch_geometric.data import Dataset, Data\n","import joblib\n","from flask import Flask, request\n","import ghhops_server as hs\n","import logging"]},{"cell_type":"code","execution_count":null,"id":"7f9ff56a-2ecd-4abf-8cce-e46da84d1eeb","metadata":{"id":"7f9ff56a-2ecd-4abf-8cce-e46da84d1eeb"},"outputs":[],"source":["device = torch.device('cpu')"]},{"cell_type":"code","execution_count":null,"id":"b173056c-5cf8-48b7-988c-b77f2e64206c","metadata":{"id":"b173056c-5cf8-48b7-988c-b77f2e64206c"},"outputs":[],"source":["app1 = Flask(__name__)\n","hops1 = hs.Hops(app1)\n","logging.basicConfig(level=logging.DEBUG)"]},{"cell_type":"code","execution_count":null,"id":"ebcab08e-b224-47bc-8823-f6e3689df23a","metadata":{"id":"ebcab08e-b224-47bc-8823-f6e3689df23a","outputId":"bf1999ef-f466-471a-9231-ea2736ca9bf0"},"outputs":[{"name":"stderr","output_type":"stream","text":["[INFO] node_scaler and edge_scaler loaded successfully.\n"]}],"source":["try:\n","    node_scaler = joblib.load('C_model/x_scaler.pkl')\n","    edge_scaler = joblib.load('C_model/edge_scaler.pkl')\n","    logging.info(\"node_scaler and edge_scaler loaded successfully.\")\n","except Exception as e:\n","    logging.error(f\"Error loading scaler: {e}\")\n","    raise"]},{"cell_type":"code","execution_count":null,"id":"714201f9-2c47-4c05-87a6-6f453e85b53e","metadata":{"id":"714201f9-2c47-4c05-87a6-6f453e85b53e"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, node_file_path, edge_file_path, transform=None, pre_transform=None):\n","        super(CustomDataset, self).__init__(None, transform, pre_transform)\n","        self.node_file_path = node_file_path\n","        self.edge_file_path = edge_file_path\n","\n","    @property\n","    def processed_file_names(self):\n","        return []\n","\n","    def len(self):\n","        return 1\n","\n","    def get(self, idx):\n","        try:\n","            nodes_df = pd.read_csv(self.node_file_path)\n","            edges_df = pd.read_csv(self.edge_file_path)\n","\n","            nodes_df = nodes_df.drop(['Node_id', 'name', 'polygon'], axis=1, errors='ignore')\n","            nodes_df = nodes_df.apply(pd.to_numeric, errors='coerce').fillna(0)\n","\n","            edges_df = edges_df.apply(pd.to_numeric, errors='coerce').fillna(0)\n","\n","            node_features = torch.tensor(nodes_df.values, dtype=torch.float)\n","            edge_index = torch.tensor(edges_df[['ID1', 'ID2']].values, dtype=torch.long).t().contiguous()\n","            edge_attr = torch.tensor(edges_df[['length']].values, dtype=torch.float)\n","\n","            graph_id = os.path.splitext(os.path.basename(self.node_file_path))[0]\n","            mydata = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, y=None)\n","            mydata.graph_id = graph_id\n","\n","            return mydata\n","        except Exception as e:\n","            logging.error(f\"Error in data loading or processing: {e}\")\n","            raise\n","\n","def apply_normalization(features, scaler):\n","    try:\n","        normalized_features = scaler.transform(features)\n","        return torch.tensor(normalized_features, dtype=torch.float)\n","    except Exception as e:\n","        logging.error(f\"Error in normalization: {e}\")\n","        raise\n","\n","def convert_and_normalize(node_csv_path, edge_csv_path, save_folder):\n","    try:\n","\n","        mydataset = CustomDataset(node_csv_path, edge_csv_path)\n","        mydata = mydataset[0]\n","\n","        normalized_x = apply_normalization(mydata.x.numpy(), node_scaler)\n","        normalized_edge_attr = apply_normalization(mydata.edge_attr.numpy(), edge_scaler)\n","\n","        normalized_graph = Data(\n","            x=normalized_x,\n","            edge_index=mydata.edge_index,\n","            edge_attr=normalized_edge_attr,\n","            graph_id=mydata.graph_id\n","        )\n","\n","        if not os.path.exists(save_folder):\n","            os.makedirs(save_folder)\n","\n","        node_filename = os.path.basename(node_csv_path)\n","        graph_filename = os.path.splitext(node_filename)[0] + \".pt\"\n","        save_path = os.path.join(save_folder, graph_filename)\n","\n","        torch.save(normalized_graph, save_path)\n","        logging.info(f\"Normalized graph data saved to {save_path}\")\n","\n","        return save_path\n","\n","    except Exception as e:\n","        logging.error(f\"Error in graph conversion, normalization, or saving: {e}\")\n","        raise"]},{"cell_type":"code","execution_count":null,"id":"46481e45-f161-450e-b0ad-1c3ff1b2cb37","metadata":{"id":"46481e45-f161-450e-b0ad-1c3ff1b2cb37"},"outputs":[],"source":["node_csv_path = \"path_to_node.csv\"\n","edge_csv_path = \"path_to_edge.csv\"\n","save_folder = \"output_folder\"\n","\n","graph_save_path = convert_and_normalize(node_csv_path, edge_csv_path, save_folder)\n","print(f\"Graph saved at: {graph_save_path}\")"]}],"metadata":{"kernelspec":{"display_name":"RL","language":"python","name":"rl"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}